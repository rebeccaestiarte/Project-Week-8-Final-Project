{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION & PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import mne\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1_normal = pd.read_csv(\"/Users/rebeccaestiarte/Desktop/IronHack/PROJECTS/Project-Week-8-Final-Project/your-project/Raw Data/museMonitor - Normal_2020-03-06--14-13-47_2885111221865233217.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/Users/rebeccaestiarte/Desktop/IronHack/PROJECTS/Project-Week-8-Final-Project/your-project/Raw Data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dataframe for each brainwave type\n",
    "Delta = test[[\"Delta_TP9\", \"Delta_AF7\", \"Delta_AF8\", \"Delta_TP10\"]]\n",
    "Theta = test[['Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10']]\n",
    "Alpha = test[['Alpha_TP9','Alpha_AF7', 'Alpha_AF8', 'Alpha_TP10']]\n",
    "Beta = test[['Beta_TP9', 'Beta_AF7', 'Beta_AF8', 'Beta_TP10']]\n",
    "Gamma = test[['Gamma_TP9', 'Gamma_AF7', 'Gamma_AF8','Gamma_TP10']]\n",
    "\n",
    "time = test[\"TimeStamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Adding mean of recording by brainwave type and adding on new column\n",
    "brainwaves = [\"Delta\", \"Theta\", \"Alpha\", \"Beta\", \"Gamma\"]\n",
    "\n",
    "def calculate_mean_bw(df, brainwave):\n",
    "    df[brainwave] = df.mean(axis=1)\n",
    "    return df[brainwave]\n",
    "\n",
    "calculate_mean_bw(Delta, \"Delta\") \n",
    "calculate_mean_bw(Theta, \"Theta\") \n",
    "calculate_mean_bw(Alpha, \"Alpha\") \n",
    "calculate_mean_bw(Beta, \"Beta\") \n",
    "calculate_mean_bw(Gamma, \"Gamma\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Concatenating all results into a dataframe\n",
    "\n",
    "result_tot = pd.concat([time, Delta, Theta, Alpha, Beta, Gamma], axis=1, sort=False)\n",
    "result_tot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tot.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tot.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theta_avg = Theta.round(5)\n",
    "theta_avg = pd.DataFrame(theta_avg[\"Theta\"].value_counts()).reset_index().rename(columns={\"index\":\"theta\"})\n",
    "theta_avg = theta_avg.drop(columns = [\"Theta\"])\n",
    "\n",
    "delta_avg = Delta.round(5)\n",
    "delta_avg = pd.DataFrame(delta_avg[\"Delta\"].value_counts()).reset_index().rename(columns={\"index\":\"delta\"})\n",
    "delta_avg = delta_avg.drop(columns = [\"Delta\"])\n",
    "\n",
    "alpha_avg = Alpha.round(5)\n",
    "alpha_avg = pd.DataFrame(alpha_avg[\"Alpha\"].value_counts()).reset_index().rename(columns={\"index\":\"alpha\"})\n",
    "alpha_avg = alpha_avg.drop(columns = [\"Alpha\"])\n",
    "\n",
    "beta_avg = Beta.round(5)\n",
    "beta_avg = pd.DataFrame(beta_avg[\"Beta\"].value_counts()).reset_index().rename(columns={\"index\":\"beta\"})\n",
    "beta_avg = beta_avg.drop(columns = [\"Beta\"])\n",
    "\n",
    "gamma_avg = Gamma.round(5)\n",
    "gamma_avg = pd.DataFrame(gamma_avg[\"Gamma\"].value_counts()).reset_index().rename(columns={\"index\":\"gamma\"})\n",
    "gamma_avg = gamma_avg.drop(columns = [\"Gamma\"])\n",
    "\n",
    "result_avg = pd.concat([theta_avg, delta_avg, alpha_avg, beta_avg, gamma_avg], axis=1, sort=False)\n",
    "result_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_avg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(result_avg[\"gamma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(result_avg[\"alpha\"])\n",
    "sns.distplot(result_avg[\"theta\"])\n",
    "sns.distplot(result_avg[\"delta\"])\n",
    "sns.distplot(result_avg[\"beta\"])\n",
    "sns.distplot(result_avg[\"gamma\"])\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "data = pd.DataFrame(result_avg[\"gamma\"])\n",
    "qqplot(data, line='s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(result)\n",
    "plt.xlabel('time (t)')\n",
    "plt.ylabel('EEG data (T)')\n",
    "\n",
    "#Adding legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = test[\"TimeStamp\"] #have to add time somehow\n",
    "data = test[[\"delta\",\"alpha\", \"beta\", \"gamma\", \"theta\"]]\n",
    "\n",
    "columns = [\"Delta_TP9\", \"Alpha_TP9\",\"Beta_TP9\", \"Gamma_TP9\", \"Theta_TP9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(time, data)\n",
    "plt.xlabel('time (t)')\n",
    "plt.ylabel('EEG data (T)')\n",
    "\n",
    "update = dict(layout=dict(showlegend=True), data=[dict(name=columns[p]) for p in data])\n",
    "py.iplot_mpl(plt.gcf(), update=update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"Delta_TP9\", \"Delta_AF7\", \"Delta_AF8\", \"Delta_TP10\",'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10','Alpha_TP9','Alpha_AF7', 'Alpha_AF8', 'Alpha_TP10','Beta_TP9', 'Beta_AF7', 'Beta_AF8', 'Beta_TP10','Gamma_TP9', 'Gamma_AF7', 'Gamma_AF8','Gamma_TP10']].head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"Delta_TP9\", \"Delta_AF7\", \"Delta_AF8\", \"Delta_TP10\",'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10','Alpha_TP9','Alpha_AF7', 'Alpha_AF8', 'Alpha_TP10','Beta_TP9', 'Beta_AF7', 'Beta_AF8', 'Beta_TP10','Gamma_TP9', 'Gamma_AF7', 'Gamma_AF8','Gamma_TP10']].tail(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(size=100)\n",
    "sns.distplot(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiline_waves(dataframe, name=\"\"):\n",
    "    \n",
    "    \"\"\"The function generates a multi-line plot of all the brainwaves\"\"\"\n",
    "    \n",
    "    x = dataframe.index #dataframe[\"TimeStamp\"]\n",
    "    df = dataframe[[\"Delta\", \"Theta\", \"Alpha\",\"Beta\", \"Gamma\"]]\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    num=0\n",
    "    for brainwave in brainwaves:\n",
    "        num+=1\n",
    "        plt.plot(x, df[brainwave], marker='', color=wave_to_color.get(brainwave), linewidth=1, alpha=0.9, label=brainwave)\n",
    "    \n",
    "    plt.legend(fontsize=15)\n",
    "    plt.title(\"EGG Brainwaves \" + name, loc='left', fontsize=20, fontweight=1, color='black')\n",
    "    plt.xlabel(\"Time\", fontsize=15)\n",
    "    plt.ylabel(\"EGG\", fontsize=15)\n",
    "    plt.ylim([-1,1.5])\n",
    "\n",
    "def line_wave(dataframe, state):\n",
    "    \n",
    "    \"\"\"The function shows graphically the pattern of each brainwave in the session\"\"\"\n",
    "    \n",
    "    x = dataframe.index #dataframe[\"TimeStamp\"]\n",
    "    df = dataframe[[\"Delta\", \"Theta\", \"Alpha\",\"Beta\", \"Gamma\"]]\n",
    "\n",
    "    for brainwave in brainwaves:\n",
    "        plt.plot(x, df[brainwave], marker='', color=wave_to_color.get(brainwave), linewidth=1, alpha=0.9, label=brainwave)\n",
    "        plt.title(f\"{brainwave, state}\") \n",
    "        plt.xlabel(\"time\", fontsize = 10)\n",
    "        plt.ylabel(f\"{brainwave}\", fontsize = 10)\n",
    "        plt.ylim([-1,1.5])\n",
    "        plt.show()\n",
    "        \n",
    "#for dataframe, name in zip(simplified_sessions_M,names_M):\n",
    "    #multiline_waves(dataframe, name)\n",
    "\n",
    "#for dataframe, name in zip(simplified_sessions_N,names_N):\n",
    "    #multiline_waves(dataframe, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load('demo_data')\n",
    "brain_fig = plot_mesh_brain(brain_data.pial_right)\n",
    "brain_data = get(gca, 'Children')\n",
    "\n",
    "# extract brain data from figure\n",
    "\n",
    "# handle vertices\n",
    "x_data = brain_data(2).Vertices(:,1)\n",
    "y_data = brain_data(2).Vertices(:,2)\n",
    "z_data = brain_data(2).Vertices(:,3)\n",
    "\n",
    "# specify how vertices connect to form the faces\n",
    "i_data = brain_data(2).Faces(:,1)-1\n",
    "j_data = brain_data(2).Faces(:,2)-1\n",
    "k_data = brain_data(2).Faces(:,3)-1\n",
    "\n",
    "# construct plotly figure\n",
    "brain_plotly_fig = plotlyfig('visible', 'off', 'strip', false, 'world_readable', false); \n",
    "brain_plotly_data.x = x_data\n",
    "brain_plotly_data.y = y_data\n",
    "brain_plotly_data.z = z_data\n",
    "brain_plotly_data.i = i_data\n",
    "brain_plotly_data.j = j_data\n",
    "brain_plotly_data.k = k_data\n",
    "brain_plotly_data.type = 'mesh3d'\n",
    "brain_plotly_data.intensity = x_data\n",
    "brain_plotly_data.colorscale = 'Electric'\n",
    "\n",
    "# add a second trace for 3D scatter points\n",
    "points_of_interest = [100, 1000, 10000]\n",
    "scatter_plotly_data.x = x_data(points_of_interest)\n",
    "scatter_plotly_data.y = y_data(points_of_interest)\n",
    "scatter_plotly_data.z = z_data(points_of_interest)\n",
    "scatter_plotly_data.marker.size=20\n",
    "scatter_plotly_data.marker.color='yellow'\n",
    "scatter_plotly_data.marker.opacity='0.4'\n",
    "scatter_plotly_data.mode = 'markers'\n",
    "scatter_plotly_data.type= 'scatter3d'\n",
    "\n",
    "# add data\n",
    "brain_plotly_fig.data = {brain_plotly_data, scatter_plotly_data};\n",
    "\n",
    "# adjust the layout\n",
    "brain_plotly_fig.layout.scene.xaxis.dtick = 30\n",
    "brain_plotly_fig.layout.scene.yaxis.dtick = 30\n",
    "brain_plotly_fig.layout.scene.zaxis.dtick = 30\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h0 : mu1 != mu2\n",
    "# H1: mu1 = mu2\n",
    "\n",
    "#https://towardsdatascience.com/hypothesis-testing-in-real-life-47f42420b1f7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPOTESIS TESTING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha Waves are stronger in meditation sessions\n",
    "h0 : AlphaM mu1 > AlphaN mu2 \n",
    "h1: mu1 = mu2\n",
    "\n",
    "https://towardsdatascience.com/hypothesis-testing-in-real-life-47f42420b1f7\n",
    "\n",
    "I will use the t-test to compare the mean of two given samples as the population parameters (mean and standard deviation) are not known. I assumed a normal distribution of the sample.\n",
    "\n",
    "I will use the independent samples t-test as I am comparing the mean for two independent groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1 = df_meditation_means.mean()\n",
    "std1 = simplified_sessions[0][[\"Delta\", \"Theta\", \"Alpha\",\"Beta\", \"Gamma\"]].std()\n",
    "n1 = simplified_sessions[0][[\"Delta\", \"Theta\", \"Alpha\",\"Beta\", \"Gamma\"]].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu2 = simplified_sessions[1][[\"Delta\", \"Theta\", \"Alpha\",\"Beta\", \"Gamma\"]].mean()\n",
    "std2 = simplified_sessions[1][[\"Delta\", \"Theta\", \"Alpha\",\"Beta\", \"Gamma\"]].std()\n",
    "n2 = simplified_sessions[1][[\"Delta\", \"Theta\", \"Alpha\",\"Beta\", \"Gamma\"]].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "t_score = stats.ttest_ind_from_stats(mu1,std1,n1, mu2,std2,n2, equal_var=False) #welch test-> not assuming equal variances in population\n",
    "t_score\n",
    "\n",
    "alpha = 0.5 #confidence interval of 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to operator (<ipython-input-2-f5ef6e5059b9>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-f5ef6e5059b9>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    t_score, p-value = stats.ttest_ind_from_stats(mu1,std1,n1, mu2,std2,n2, equal_var=False) #welch test-> not assuming equal variances in population\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to operator\n"
     ]
    }
   ],
   "source": [
    "mu1 = df_meditation_means[\"Alpha\"].mean()\n",
    "std1 = df_meditation_means[\"Alpha\"].std()\n",
    "n1 = df_meditation_means[\"Alpha\"].shape[0]\n",
    "\n",
    "mu2 = df_normal_means[\"Alpha\"].mean()\n",
    "std2 = df_normal_means[\"Alpha\"].std()\n",
    "n2 = df_normal_means[\"Alpha\"].shape[0]\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "t_score, p-value = stats.ttest_ind_from_stats(mu1,std1,n1, mu2,std2,n2, equal_var=False) #welch test-> not assuming equal variances in population\n",
    "print(t_score, p-value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-3-b6eee83b5c71>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-b6eee83b5c71>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    H0: m1 â m2 = 0           H1: m1 â m2 > 0\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "H0: m1 â m2 = 0           H1: m1 â m2 > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if p-value < 0.05:\n",
    "    print(accept H1)\n",
    "\n",
    "\n",
    "Calculations from StatCrunch: t = 1.80, p-value = 0.0392 < .05 ---> Accept Ha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Rule: Accept Ha if the calculated p-value < .05.\n",
    "\n",
    "Interpretation: At the .05 level of significance I conclude that the true mean final average of students using the computer in this statistics course is higher than those not using the computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USELESS CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_std_bw(df, brainwave):\n",
    "    df[brainwave] = df.std(axis=1)\n",
    "    return df\n",
    "\n",
    "calculate_std_bw(Delta, \"Delta\") \n",
    "calculate_std_bw(Theta, \"Theta\") \n",
    "calculate_std_bw(Alpha, \"Alpha\") \n",
    "calculate_std_bw(Beta, \"Beta\") \n",
    "calculate_std_bw(Gamma, \"Gamma\")\n",
    "\n",
    "theta_std = Theta.round(5)\n",
    "theta_std = pd.DataFrame(theta_std[\"Theta\"].value_counts()).reset_index().rename(columns={\"index\":\"thetha\"})\n",
    "theta_std = theta_std.drop(columns = [\"Theta\"])\n",
    "\n",
    "delta_std = Delta.round(5)\n",
    "delta_std = pd.DataFrame(delta_std[\"Delta\"].value_counts()).reset_index().rename(columns={\"index\":\"delta\"})\n",
    "delta_std = delta_std.drop(columns = [\"Delta\"])\n",
    "\n",
    "alpha_std = Alpha.round(5)\n",
    "alpha_std = pd.DataFrame(alpha_std[\"Alpha\"].value_counts()).reset_index().rename(columns={\"index\":\"alpha\"})\n",
    "alpha_std = alpha_std.drop(columns = [\"Alpha\"])\n",
    "\n",
    "beta_std = Beta.round(5)\n",
    "beta_std = pd.DataFrame(beta_std[\"Beta\"].value_counts()).reset_index().rename(columns={\"index\":\"beta\"})\n",
    "beta_std = beta_std.drop(columns = [\"Beta\"])\n",
    "\n",
    "gamma_std = Gamma.round(5)\n",
    "gamma_std = pd.DataFrame(gamma_std[\"Gamma\"].value_counts()).reset_index().rename(columns={\"index\":\"gamma\"})\n",
    "gamma_std = gamma_std.drop(columns = [\"Gamma\"])\n",
    "\n",
    "result_std = pd.concat([theta_std, delta_std, alpha_std, beta_std, gamma_std], axis=1, sort=False)\n",
    "result_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simplified_sessions_N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-461180eff3bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimplified_sessions_N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscaled_sessions_N\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimplified_sessions_N\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simplified_sessions_N' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "simplified_sessions_N\n",
    "\n",
    "scaled_sessions_N =[]\n",
    "for dataframe in simplified_sessions_N:\n",
    "    scaler = StandardScaler()\n",
    "    numpy = scaler.fit_transform(dataframe)  \n",
    "    test = pd.DataFrame(numpy, columns=[\"Delta\", \"Theta\", \"Alpha\", \"Beta\", \"Gamma\", \"Activity\"])\n",
    "    test = test[(np.abs(test) < 3).all(axis=1)]\n",
    "    scaled_sessions_N.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataframe into features and target with 80-20 split\n",
    "Dividing dataset by inputs and output and then using the 80% 20% split to train and test using different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20 , shuffle = True, random_state=146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing effect of different depth parameters on model \n",
    "\n",
    "r2_scores_train = []\n",
    "r2_scores_test = []\n",
    "max_depth_par = [2,3,4,5,6,7,8]\n",
    "for parameter in max_depth_par:\n",
    "    rfr = RandomForestClassifier(max_depth=parameter)\n",
    "    rfr.fit(X_train, y_train)\n",
    "    \n",
    "    y_predict_test = rfr.predict(X_test)\n",
    "    y_predict_train = rfr.predict(X_train)\n",
    "    \n",
    "    scores_test =  r2_score(y_test, y_predict_test)\n",
    "    scores_train =  r2_score(y_train, y_predict_train)\n",
    "    \n",
    "    print(\"test: max_depth\", parameter)\n",
    "    print (scores_test)\n",
    "    \n",
    "    print(\"train: max_depth\", parameter)\n",
    "    print (scores_train)\n",
    "    \n",
    "    var = (scores_train-scores_test)**2\n",
    "    print(\"absolute difference:\", var)\n",
    "    \n",
    "    print(\"-------------------------------------\")\n",
    "\n",
    "    r2_scores_test.append(scores_test)\n",
    "    r2_scores_train.append(scores_train)\n",
    "        \n",
    "plt.plot(max_depth_par, r2_scores_train, label='r2_score train')\n",
    "plt.plot(max_depth_par, r2_scores_test, label='r2_score test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing effect of different neighbor parameters on model \n",
    "\n",
    "neighbors_par = [1,2,3,4,5,6,7]\n",
    "\n",
    "for neighbor in neighbors_par:\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbor).fit(X_train, y_train)\n",
    "    \n",
    "    knn_y_predict_test = knn.predict(X_test)\n",
    "    knn_y_predict_train = knn.predict(X_train)\n",
    "    \n",
    "    scores_test =  r2_score(y_test, knn_y_predict_test)\n",
    "    scores_train =  r2_score(y_train, knn_y_predict_train)\n",
    "    \n",
    "    print(\"test: n_neighbors\", neighbor)\n",
    "    print (scores_test)\n",
    "    \n",
    "    print(\"train: n_neighbors\", neighbor)\n",
    "    print (scores_train)\n",
    "    \n",
    "    var = (scores_train-scores_test)**2\n",
    "    print(\"absolute difference:\", var)\n",
    "    \n",
    "    print(\"-------------------------------------\")\n",
    "\n",
    "    r2_scores_test.append(scores_test)\n",
    "    r2_scores_train.append(scores_train)\n",
    "        \n",
    "plt.plot(neighbors_par, r2_scores_train, label='r2_score train')\n",
    "plt.plot(neighbors_par, r2_scores_test, label='r2_score test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
